{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "quantitative-pencil",
   "metadata": {},
   "source": [
    "## The Sparks Foundation :: Computer Vision & IoT Internship (GRIP JUNE'21)\n",
    "\n",
    "\n",
    "### Name : Mirza Zulfiqar Ali Jaffer Ali\n",
    "\n",
    "### TASK 1 : Object Detection "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "third-flower",
   "metadata": {},
   "source": [
    "#### First Including all required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "tough-pocket",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# From Tensorflow Object Detection API\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.utils import ops as utils_ops\n",
    "\n",
    "%matplotlib inline\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stunning-charter",
   "metadata": {},
   "source": [
    "#### Function to convert image into required shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "superior-contract",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_into_array(image):\n",
    "    (im_height, im_width) = image.shape[0:-1]\n",
    "    return np.array(image.reshape((1, im_height, im_width, 3)).astype(np.uint8))    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sonic-relaxation",
   "metadata": {},
   "source": [
    "#### At this point I already installed Tensorflow Object Detection API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "sustainable-tomorrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_LABELS = '/home/zulfiqar110/models/research/object_detection/data/mscoco_label_map.pbtxt'\n",
    "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upper-fluid",
   "metadata": {},
   "source": [
    "#### List of Models to choose from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "secondary-mailman",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = {'EfficientDet D0 512x512':'https://tfhub.dev/tensorflow/efficientdet/d0/1',\n",
    "          'SSD MobileNet v2 320x320' : 'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2',\n",
    "          'SSD MobileNet V2 FPNLite 320x320' : 'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/fpnlite_320x320/1'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "documented-somalia",
   "metadata": {},
   "source": [
    "#### Loading the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abroad-furniture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EfficientDet D0 512x512 Loaded]\n",
      "Handler at https://tfhub.dev/tensorflow/efficientdet/d0/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Importing a function (__inference___call___32344) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_EfficientDet-D0_layer_call_and_return_conditional_losses_97451) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_77595) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_EfficientDet-D0_layer_call_and_return_conditional_losses_103456) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_EfficientDet-D0_layer_call_and_return_conditional_losses_93843) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_EfficientDet-D0_layer_call_and_return_conditional_losses_107064) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_75975) with ops with custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL LOADED SUCCESSFULLY\n"
     ]
    }
   ],
   "source": [
    "Model_index = 0\n",
    "Model = list(MODELS.keys())\n",
    "handle = list(MODELS.values())\n",
    "\n",
    "print(f'{Model[Model_index]} Loaded\\nHandler at {handle[Model_index]}')\n",
    "hub_model = hub.load(handle[Model_index])\n",
    "print('MODEL LOADED SUCCESSFULLY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "successful-helena",
   "metadata": {},
   "source": [
    "### Now let's test on a Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "approved-baltimore",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'Path of your video here'\n",
    "source = cv2.VideoCapture(PATH)\n",
    "while True:\n",
    "    ret, frame = source.read()\n",
    "    img = image_into_array(frame)\n",
    "    result = hub_model(img)\n",
    "    result = {key:values.numpy() for key, values in result.items()}\n",
    "    label_id_offset = 0\n",
    "    image_np_with_detections = img.copy()\n",
    "\n",
    "    # Use keypoints if available in detections\n",
    "    keypoints, keypoint_scores = None, None\n",
    "    if 'detection_keypoints' in result:\n",
    "        keypoints = result['detection_keypoints'][0]\n",
    "        keypoint_scores = result['detection_keypoint_scores'][0]\n",
    "\n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "            image_np_with_detections[0],\n",
    "            result['detection_boxes'][0],\n",
    "            (result['detection_classes'][0] + label_id_offset).astype(int),\n",
    "            result['detection_scores'][0],\n",
    "            category_index,\n",
    "            use_normalized_coordinates=True,\n",
    "            max_boxes_to_draw=20,\n",
    "            min_score_thresh=.30,\n",
    "            agnostic_mode=False,\n",
    "            keypoint_scores=keypoint_scores)\n",
    "    frame = cv2.resize(image_np_with_detections[0],(800,500))\n",
    "    cv2.imshow(\"VIDEO\",frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "  # print(img.shape)\n",
    "source.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
